{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ff27e4",
   "metadata": {},
   "source": [
    "# テンソル\n",
    "テンソルは、配列や行列に非常によく似た特殊なデータ構造です。  \n",
    "PyTorch では、テンソルを使用してモデルの入力と出力、およびモデルのパラメータをエンコードします。\n",
    "\n",
    "テンソルはNumPy のndarrayに似ていますが、テンソルは GPU やその他のハードウェア アクセラレータで実行できる点が異なります。  \n",
    "実際、テンソルと NumPy 配列は多くの場合、同じ基礎メモリを共有できるため、データをコピーする必要がありません ( 「NumPy とのブリッジ」を参照)。  \n",
    "テンソルは自動微分にも最適化されています (これについては、 Autograd のセクションで後ほど詳しく説明します )。  \n",
    "ndarray に精通していれば、Tensor API もすぐに使いこなせるでしょう。  \n",
    "そうでない場合は、このまま読み進めてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474e601e",
   "metadata": {},
   "source": [
    "# テンソルの初期化\n",
    "テンソルはさまざまな方法で初期化できます。次の例を見てみましょう。\n",
    "\n",
    "## データから直接\n",
    "\n",
    "テンソルはデータから直接作成できます。データ型は自動的に推測されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d381207d006997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:13:59.483501Z",
     "start_time": "2025-02-10T23:13:59.478379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.6045, 0.1330],\n",
      "        [0.7897, 0.6708]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ac69f3",
   "metadata": {},
   "source": [
    "## NumPy配列から\n",
    "\n",
    "テンソルは NumPy 配列から作成できます (逆も同様です - Bridge with NumPy を参照)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d91830",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8262b",
   "metadata": {},
   "source": [
    "## 別のテンソルから:\n",
    "\n",
    "新しいテンソルは、明示的にオーバーライドされない限り、引数テンソルのプロパティ (形状、データ型) を保持します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a409524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.8592, 0.0056],\n",
      "        [0.2401, 0.4620]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431a540",
   "metadata": {},
   "source": [
    "## ランダム値または定数値の場合:\n",
    "\n",
    "shapeテンソルの次元のタプルです。以下の関数では、出力テンソルの次元を決定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a022ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.1346, 0.4219, 0.0915],\n",
      "        [0.7220, 0.8685, 0.0719]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b529c",
   "metadata": {},
   "source": [
    "# テンソルの属性\n",
    "テンソル属性は、テンソルの形状、データ型、およびテンソルが保存されているデバイスを記述します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551e5387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51c445",
   "metadata": {},
   "source": [
    "# テンソルの演算\n",
    "ここでは、算術、線形代数、行列操作 (転置、インデックス作成、スライス)、サンプリングなど、1200 を超えるテンソル演算が包括的に説明されています。\n",
    "\n",
    "これらの各操作は、CPU と、CUDA、MPS、MTIA、XPU などのアクセラレータで実行できます 。  \n",
    "Colab を使用している場合は、[ランタイム] > [ランタイム タイプの変更] > [GPU] に移動してアクセラレータを割り当てます。\n",
    "\n",
    "デフォルトでは、テンソルは CPU 上に作成されます。  \n",
    " .toアクセラレータの可用性を確認した後、メソッドを使用してテンソルをアクセラレータに明示的に移動する必要があります。  \n",
    " デバイス間で大きなテンソルをコピーすると、時間とメモリの面でコストがかかる可能性があることに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f63fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the current accelerator if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(torch.device('cuda'))\n",
    "else:\n",
    "    tensor = tensor.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4954291",
   "metadata": {},
   "source": [
    "リストにある操作をいくつか試してみてください。NumPy API に慣れている方なら、Tensor API も簡単に使えるでしょう。\n",
    "\n",
    "## 標準的な numpy のようなインデックスとスライス:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea4fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cefa2d",
   "metadata": {},
   "source": [
    "## テンソルの結合 \n",
    "をtorch.cat使用すると、指定された次元に沿ってテンソルのシーケンスを連結できます。　　\n",
    "とは微妙に異なる別のテンソル結合演算子であるtorch.stacktorch.catも参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245d077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33db0c",
   "metadata": {},
   "source": [
    "# 算術演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d5bdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347ef69",
   "metadata": {},
   "source": [
    "# 単一要素テンソル\n",
    "単一要素テンソルがある場合、たとえばテンソルのすべての値を 1 つの値に集約すると、次のようにして Python 数値に変換できますitem()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2017d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e92e240",
   "metadata": {},
   "source": [
    "## インプレース \n",
    "演算 結果をオペランドに格納する演算は、インプレースと呼ばれます。  \n",
    "これらは_接尾辞で示されます。たとえばx.copy_(y)、x.t_()、 は を変更しますx。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634118cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8021, 0.7149, 0.9758, 0.9357],\n",
      "        [0.3192, 0.0297, 0.5533, 0.5603],\n",
      "        [0.4547, 0.5924, 0.6394, 0.3965]]) \n",
      "\n",
      "tensor([[5.8021, 5.7149, 5.9758, 5.9357],\n",
      "        [5.3192, 5.0297, 5.5533, 5.5603],\n",
      "        [5.4547, 5.5924, 5.6394, 5.3965]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c8c79e",
   "metadata": {},
   "source": [
    "インプレース演算はメモリをいくらか節約しますが、履歴がすぐに失われるため導関数を計算するときに問題が発生する可能性があります。\n",
    "したがって、インプレース演算の使用は推奨されません。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0249b46",
   "metadata": {},
   "source": [
    "# NumPy を使用したブリッジ\n",
    "CPU 上のテンソルと NumPy 配列は、基礎となるメモリの場所を共有できるため、一方を変更するともう一方も変更されます。\n",
    "\n",
    "## テンソルからNumPy配列へ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1be048df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f32c1",
   "metadata": {},
   "source": [
    "テンソルの変更は NumPy 配列に反映されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ea8756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6878ca7",
   "metadata": {},
   "source": [
    "## NumPy配列からTensorへ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b08af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11155b97",
   "metadata": {},
   "source": [
    "NumPy 配列の変更はテンソルに反映されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cac743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
